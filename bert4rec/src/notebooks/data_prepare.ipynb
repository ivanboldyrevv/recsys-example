{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./raw_data/data.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 136534 duplicate rows that need to be removed.\n",
      "The dataset contains 5225 duplicate rows that need to be removed.\n",
      "raw data len: 541909; cleaned data len: 391150\n"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING & TRANSFORMATION\n",
    "\n",
    "raw_data_length = len(df)\n",
    "\n",
    "# ---------------------------- Drop nan ------------------------------------------------------\n",
    "print(f\"The dataset contains {df.isnull().sum().sum()} duplicate rows that need to be removed.\")\n",
    "df = df.dropna(subset=[\"Description\", \"CustomerID\"])\n",
    "assert df.isnull().sum().sum() == 0\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# ---------------------------- Drop duplciates -----------------------------------------------\n",
    "\n",
    "print(f\"The dataset contains {df.duplicated().sum()} duplicate rows that need to be removed.\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "assert df.duplicated().sum() == 0\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------- Canceled transaction cut ---------------------------------------\n",
    "df[\"Transaction_Status\"] = np.where(df[\"InvoiceNo\"].astype(str).str.startswith(\"C\"), \"Cancelled\", \"Completed\").copy()\n",
    "df = df[df[\"Transaction_Status\"] == \"Completed\"]\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------- delete anomalous stock codes ------------------------------------\n",
    "unique_stock_codes = df['StockCode'].unique()\n",
    "numeric_char_counts_in_unique_codes = pd.Series(unique_stock_codes).apply(lambda x: sum(c.isdigit() for c in str(x))).value_counts()\n",
    "anomalous_stock_codes = [code for code in unique_stock_codes if sum(c.isdigit() for c in str(code)) in (0, 1)]\n",
    "df = df[~df['StockCode'].isin(anomalous_stock_codes)]\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Resetting the index of the cleaned dataset\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# delete unitprice == 0\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "\n",
    "print(f\"raw data len: {raw_data_length}; cleaned data len: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINERING\n",
    "\n",
    "\"\"\"\n",
    "    Recency (R): This metric indicates how recently a customer has made a purchase.\n",
    "    A lower recency value means the customer has purchased more recently, indicating higher engagement with the brand.\n",
    "\n",
    "    Frequency (F): This metric signifies how often a customer makes a purchase within a certain period.\n",
    "    A higher frequency value indicates a customer who interacts with the business more often, suggesting higher loyalty or satisfaction.\n",
    "\n",
    "    Monetary (M): This metric represents the total amount of money a customer has spent over a certain period.\n",
    "    Customers who have a higher monetary value have contributed more to the business, indicating their potential high lifetime value.\n",
    "\"\"\"\n",
    "# --------------------------------- RECENCY ----------------------------------------------------------\n",
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "df[\"InvoiceDay\"] = df[\"InvoiceDate\"].dt.date\n",
    "\n",
    "customer_data = df.groupby(\"CustomerID\")[\"InvoiceDay\"].max().reset_index()\n",
    "most_recent_date = df[\"InvoiceDay\"].max()\n",
    "\n",
    "customer_data[\"InvoiceDay\"] = pd.to_datetime(customer_data[\"InvoiceDay\"])\n",
    "most_recent_date = pd.to_datetime(most_recent_date)\n",
    "\n",
    "customer_data[\"Days_Since_Last_Purchase\"] = (most_recent_date - customer_data[\"InvoiceDay\"]).dt.days\n",
    "customer_data\n",
    "\n",
    "customer_data.drop(columns=[\"InvoiceDay\"], inplace=True)\n",
    "\n",
    "# ------------------------------- FREQ --------------------------------------------------------------\n",
    "\n",
    "total_transactions = df.groupby(\"CustomerID\")[\"InvoiceNo\"].nunique().reset_index()\n",
    "total_transactions.rename(columns={\"InvoiceNo\": \"Total_Transactions\"}, inplace=True)\n",
    "\n",
    "total_products_purchased = df.groupby(\"CustomerID\")[\"Quantity\"].sum().reset_index()\n",
    "total_products_purchased.rename(columns={\"Quantity\": \"Total_Products_Purchased\"}, inplace=True)\n",
    "\n",
    "customer_data = pd.merge(customer_data, total_transactions, on=\"CustomerID\")\n",
    "customer_data = pd.merge(customer_data, total_products_purchased, on=\"CustomerID\")\n",
    "\n",
    "# ---------------------------- MONETARY -------------------------------------------------------------\n",
    "\n",
    "df[\"Total_Spend\"] = df[\"UnitPrice\"] * df[\"Quantity\"]\n",
    "total_spend = df.groupby(\"CustomerID\")[\"Total_Spend\"].sum().reset_index()\n",
    "\n",
    "average_transaction_value = total_spend.merge(total_transactions, on=\"CustomerID\")\n",
    "average_transaction_value[\"Average_Transaction_Value\"] = average_transaction_value[\"Total_Spend\"] / average_transaction_value[\"Total_Transactions\"]\n",
    "\n",
    "customer_data = pd.merge(customer_data, total_spend, on=\"CustomerID\")\n",
    "customer_data = pd.merge(customer_data, average_transaction_value[[\"CustomerID\", \"Average_Transaction_Value\"]], on=\"CustomerID\")\n",
    "\n",
    "customer_data.head()\n",
    "\n",
    "# ------------------------- FILTERING --------------------------------------------------------------\n",
    "\n",
    "customer_data = customer_data[customer_data[\"Days_Since_Last_Purchase\"] < 55]\n",
    "customer_data = customer_data[(customer_data[\"Total_Spend\"] > 10) & (customer_data[\"Total_Spend\"] < 2000)]\n",
    "customer_data = customer_data[customer_data[\"Total_Transactions\"] > 3]\n",
    "\n",
    "customers = customer_data[\"CustomerID\"].to_list()\n",
    "\n",
    "df = df[df[\"CustomerID\"].isin(customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to timestamp\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "df[\"Timestamp\"] = df_copy[\"InvoiceDate\"].astype(np.int64) // 10 ** 9\n",
    "\n",
    "df = df.sort_values(by=\"Timestamp\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./raw_data/prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE ITEM TABLE TO SQL\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "def execute_many(conn, df, table):\n",
    "    tuples = [tuple(x) for x in df.values]\n",
    "    cols = ','.join(list(df.columns))\n",
    "\n",
    "    query  = \"INSERT INTO %s(%s) VALUES(%%s,%%s, %%s)\" % (table, cols)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.executemany(query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres_db user=postgres_user password=postgres_password\", port=5430)\n",
    "\n",
    "# reference to .py file -> fetch_img_url.py\n",
    "# create table with images\n",
    "\n",
    "item_images = pd.read_csv(\"./image_item.csv\")\n",
    "item_images = item_images[[\"item_id\", \"image_url\"]]\n",
    "\n",
    "items_to_sql = df[[\"StockCode\", \"Description\"]]\n",
    "\n",
    "items_to_sql = items_to_sql.rename(columns={\"StockCode\": \"item_id\", \"Description\": \"description\"})\n",
    "items_to_sql = items_to_sql.drop_duplicates(subset=[\"item_id\"])\n",
    "\n",
    "merged = pd.merge(item_images, items_to_sql, on=\"item_id\")\n",
    "merged = merged[[\"item_id\", \"description\", \"image_url\"]]\n",
    "\n",
    "execute_many(conn, merged, \"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391182</th>\n",
       "      <td>12680.0</td>\n",
       "      <td>22138</td>\n",
       "      <td>1323435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391168</th>\n",
       "      <td>12680.0</td>\n",
       "      <td>22631</td>\n",
       "      <td>1323435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391177</th>\n",
       "      <td>12680.0</td>\n",
       "      <td>23256</td>\n",
       "      <td>1323435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391181</th>\n",
       "      <td>12680.0</td>\n",
       "      <td>23255</td>\n",
       "      <td>1323435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391180</th>\n",
       "      <td>12680.0</td>\n",
       "      <td>23254</td>\n",
       "      <td>1323435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>15862.0</td>\n",
       "      <td>22451</td>\n",
       "      <td>1291202460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>15862.0</td>\n",
       "      <td>22766</td>\n",
       "      <td>1291202460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>15862.0</td>\n",
       "      <td>22100</td>\n",
       "      <td>1291202460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>15862.0</td>\n",
       "      <td>22810</td>\n",
       "      <td>1291202460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>15862.0</td>\n",
       "      <td>22110</td>\n",
       "      <td>1291202460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token item_id:token  timestamp:float\n",
       "391182        12680.0         22138       1323435000\n",
       "391168        12680.0         22631       1323435000\n",
       "391177        12680.0         23256       1323435000\n",
       "391181        12680.0         23255       1323435000\n",
       "391180        12680.0         23254       1323435000\n",
       "...               ...           ...              ...\n",
       "312           15862.0         22451       1291202460\n",
       "311           15862.0         22766       1291202460\n",
       "310           15862.0         22100       1291202460\n",
       "340           15862.0         22810       1291202460\n",
       "308           15862.0         22110       1291202460\n",
       "\n",
       "[52656 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare to atomic format\n",
    "df = df[[\"CustomerID\", \"StockCode\", \"Timestamp\"]]\n",
    "df = df.rename(columns={\"CustomerID\": \"user_id:token\", \"StockCode\": \"item_id:token\", \"Timestamp\": \"timestamp:float\"})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to recbole atomic file\n",
    "df.to_csv(\"dataset/data/data.inter\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
