{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\projects\\recsys\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import BERT4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Dec 15:29    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./dataset\\data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 0, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = mask_itemseq\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.2\n",
      "attn_dropout_prob = 0.2\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "mask_ratio = 0.2\n",
      "loss_type = CE\n",
      "ft_ratio = 0.5\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./dataset\\data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 0, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = mask_itemseq\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.2\n",
      "attn_dropout_prob = 0.2\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "mask_ratio = 0.2\n",
      "loss_type = CE\n",
      "ft_ratio = 0.5\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"data_path\": \"./dataset\",\n",
    "    \"USER_ID_FIELD\": \"user_id\",\n",
    "    \"ITEM_ID_FIELD\": \"item_id\",\n",
    "    \"TIME_FIELD\": \"timestamp\",\n",
    "    \"train_neg_sample_args\": None,\n",
    "    \"load_col\": {\"inter\": [\"user_id\", \"item_id\", \"timestamp\"]},\n",
    "    \"neg_sampling\": None,\n",
    "    \"epochs\": 50,\n",
    "    \"eval_args\": {\n",
    "        \"split\": {\"RS\": [9, 0, 1]},\n",
    "        \"group_by\": \"user\",\n",
    "        \"order\": \"TO\",\n",
    "        \"mode\": \"full\"}\n",
    "    }\n",
    "\n",
    "config = Config(model=\"BERT4Rec\", dataset=\"data\", config_dict=params)\n",
    "\n",
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "init_logger(config)\n",
    "\n",
    "logger = getLogger()\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(c_handler)\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "# model loading and initialization\n",
    "model = BERT4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "external_user_ids = dataset.id2token(dataset.uid_field, list(range(dataset.user_num)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n"
     ]
    }
   ],
   "source": [
    "topk_items = []\n",
    "for internal_user_id in list(range(dataset.user_num))[1:]:\n",
    "    _, topk_iid_list = full_sort_topk([internal_user_id], model, test_data, k=12, device=config['device'])\n",
    "    last_topk_iid_list = topk_iid_list[-1]\n",
    "    external_item_list = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n",
    "    topk_items.append(external_item_list)\n",
    "print(len(topk_items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The batch_size of interaction: 88\n",
       "    user_id, torch.Size([88]), cpu, torch.int64\n",
       "    item_id, torch.Size([88]), cpu, torch.int64\n",
       "    timestamp, torch.Size([88]), cpu, torch.float32\n",
       "    item_length, torch.Size([88]), cpu, torch.int64\n",
       "    item_id_list, torch.Size([88, 50]), cpu, torch.int64\n",
       "    timestamp_list, torch.Size([88, 50]), cpu, torch.float32\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "index = np.isin(dataset[dataset.uid_field].numpy(), [3])\n",
    "input_interaction = dataset[index]\n",
    "input_interaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iid_list = dataset.token2id(dataset.iid_field, [\"22457\"])\n",
    "iid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[5.5296, 4.9989, 4.8446, 4.7937, 4.7579, 4.7471, 4.6589, 4.4890, 4.4311,\n",
       "         4.3549]], device='cuda:0', grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[ 330,  966,  705,  234, 2930,  578,  865, 1996,  511, 1034]],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from recbole.data.interaction import Interaction\n",
    "import numpy as np\n",
    "\n",
    "index = np.isin(dataset[dataset.uid_field].numpy(), [104])\n",
    "input_interaction = dataset[index]\n",
    "input_interaction\n",
    "\n",
    "def _pad_item_sequence_to_max_length(item_sequence):\n",
    "    # Если последовательность меньше максимальной длины предметов модели\n",
    "    new_tensor = torch.zeros((1, model.max_seq_length),dtype=torch.int)\n",
    "    new_tensor[:, :6] = torch.tensor([item_sequence])\n",
    "    return new_tensor\n",
    "\n",
    "test = {\n",
    "            'item_id_list': _pad_item_sequence_to_max_length(iid_list),\n",
    "            'item_length': torch.tensor([len(iid_list)])\n",
    "        }\n",
    "\n",
    "new_inter = Interaction(test)\n",
    "new_inter = new_inter.to(config['device'])\n",
    "\n",
    "new_scores = model.full_sort_predict(new_inter)\n",
    "new_scores = new_scores.view(-1, test_data.dataset.item_num)\n",
    "new_scores[:, 0] = -np.inf  # set scores of [pad] to -inf\n",
    "\n",
    "torch.topk(new_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3097"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.item_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['84800S', '21669', '22040', '22710', '84763', '22148', '22149',\n",
       "        '22697', '21500', '22087'], dtype='<U7')]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _pad_item_sequence_to_max_length(item_sequence: list):\n",
    "    # Если последовательность меньше максимальной длины предметов модели\n",
    "    new_tensor = torch.zeros((1, model.max_seq_length),dtype=torch.int)\n",
    "    new_tensor[:, :len(item_sequence)] = torch.tensor([item_sequence])\n",
    "    return new_tensor\n",
    "\n",
    "def _predict(item_sequence: list, model: BERT4Rec):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        inter = Interaction({\n",
    "            \"item_id_list\": _pad_item_sequence_to_max_length(item_sequence),\n",
    "            \"item_length\": torch.tensor([len(item_sequence)])\n",
    "        }).to(model.device)\n",
    "\n",
    "        scores = model.full_sort_predict(inter)\n",
    "        scores = scores.view(-1, dataset.item_num)\n",
    "        scores[:, 0] = -np.inf\n",
    "    \n",
    "    item_score, item_inner_iid = torch.topk(scores, 10)\n",
    "\n",
    "    return item_score, item_inner_iid\n",
    "\n",
    "iid_list = dataset.token2id(dataset.iid_field, [\"72133\", \"22457\", \"85049E\", \"17090D\", \"84763\"])\n",
    "_, indices = _predict(iid_list, model)\n",
    "\n",
    "indices = indices.view(10).tolist()\n",
    "raw_iid = [dataset.id2token(dataset.iid_field, [i for i in indices])]\n",
    "raw_iid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(iid='84800S', score=5.516401767730713), Prediction(iid='21669', score=5.496496200561523), Prediction(iid='22040', score=5.183253288269043), Prediction(iid='22710', score=5.145431995391846), Prediction(iid='84763', score=5.137936592102051), Prediction(iid='22148', score=5.118233680725098), Prediction(iid='22149', score=4.9793853759765625), Prediction(iid='22697', score=4.9715166091918945), Prediction(iid='21500', score=4.821472644805908), Prediction(iid='22087', score=4.715353488922119), Prediction(iid='21715', score=4.706779479980469), Prediction(iid='22698', score=4.674909591674805), Prediction(iid='22423', score=4.617501258850098), Prediction(iid='22859', score=4.597131729125977), Prediction(iid='21671', score=4.5643744468688965), Prediction(iid='84800L', score=4.558695316314697), Prediction(iid='84625C', score=4.548460483551025), Prediction(iid='22805', score=4.533363342285156), Prediction(iid='23034', score=4.525113105773926), Prediction(iid='21926', score=4.489747524261475), Prediction(iid='22690', score=4.450157642364502), Prediction(iid='20803', score=4.443655490875244), Prediction(iid='21718', score=4.414166450500488), Prediction(iid='22963', score=4.20646333694458), Prediction(iid='22570', score=4.184699058532715), Prediction(iid='22750', score=4.1764912605285645), Prediction(iid='22585', score=4.138955593109131), Prediction(iid='47590A', score=4.092265605926514), Prediction(iid='22255', score=4.083715915679932), Prediction(iid='21381', score=4.066717147827148)]\n"
     ]
    }
   ],
   "source": [
    "from recbole.model.abstract_recommender import SequentialRecommender\n",
    "from recbole.data.interaction import Interaction\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Prediction:\n",
    "    iid: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class RecommendationHandler:\n",
    "    def __init__(self, dataset, model: SequentialRecommender) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "\n",
    "    def build_recos(self, item_sequence: list, k: int) -> List[Prediction]:\n",
    "        \"\"\"\n",
    "            Generates recommendations based on a sequence of external item indices.\n",
    "\n",
    "            Args:\n",
    "                item_sequence: A list of external item indices.\n",
    "\n",
    "            Returns:\n",
    "                A list of type Prediction.\n",
    "        \"\"\"\n",
    "        \n",
    "        inner_ids = self.dataset.token2id(dataset.iid_field, item_sequence)\n",
    "\n",
    "        scores, inner_iid = self._predict(inner_ids, k)\n",
    "\n",
    "        scores = scores.view(k).tolist()\n",
    "        indices = inner_iid.view(k).tolist()\n",
    "        raw_iid = [self.dataset.id2token(self.dataset.iid_field, indices)]\n",
    "\n",
    "        return [Prediction(iid, score) for iid, score in list(zip(raw_iid[0], scores))]\n",
    "\n",
    "    def _predict(self, item_sequence: list, k: int):\n",
    "        \"\"\"\n",
    "            Calculates the top k items for a given sequence of internal indices.\n",
    "\n",
    "            Args:\n",
    "                item_sequence: A list of internal indices of items.\n",
    "                k: amount of items.\n",
    "\n",
    "            Returns:\n",
    "                A tuple containing two lists:\n",
    "                    - The first list contains the internal indices of the top k items.\n",
    "                    - The second list contains the scores of these items.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            inter = self._prepare_interaction_data(item_sequence)\n",
    "\n",
    "            scores = self.model.full_sort_predict(inter)\n",
    "            scores = scores.view(-1, self.dataset.item_num)\n",
    "            scores[:, 0] = -np.inf\n",
    "\n",
    "        item_score, item_inner_iid = torch.topk(scores, k)\n",
    "        return item_score, item_inner_iid\n",
    "    \n",
    "    def _prepare_interaction_data(self, item_sequence: List[int]) -> Interaction:        \n",
    "        return Interaction({\n",
    "            \"item_id_list\": self._pad_item_sequence_to_max_length(item_sequence),\n",
    "            \"item_length\": torch.tensor([len(item_sequence)])\n",
    "        }).to(self.model.device)        \n",
    "\n",
    "    def _pad_item_sequence_to_max_length(self, item_sequence: list):\n",
    "        # Если последовательность меньше максимальной длины предметов модели\n",
    "        new_tensor = torch.zeros((1, self.model.max_seq_length), dtype=torch.int64)\n",
    "        new_tensor[:, :len(item_sequence)] = torch.tensor([item_sequence])\n",
    "        return new_tensor\n",
    "\n",
    "\n",
    "r_handler = RecommendationHandler(dataset, model)\n",
    "r = r_handler.build_recos([\"72133\", \"22457\", \"85049E\", \"17090D\", \"84763\"], 30)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
